{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a813d68-a7bf-4129-9d9a-d0d16d73382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib as mtp\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "357f2749-34b0-49fc-8b20-1a0d6260767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dir = os.path.join(\"/homeLocal/jpulzdeoliveira/datasets\")\n",
    "pastis_dir = os.path.join(datasets_dir, \"PASTIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035ea262-359f-447a-b71c-792dfed9f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda as backend device\n"
     ]
    }
   ],
   "source": [
    "backend_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {backend_device} as backend device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adb60e8-ef7e-4964-baf0-23a3f11067a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "from torch.utils.data import Dataset, random_split    \n",
    "\n",
    "def pool_processing(args):\n",
    "    params, selection = args\n",
    "    for _, patch in selection.iterrows():\n",
    "        patch_id, timestamps = patch\n",
    "        data = np.load(\n",
    "            os.path.join(params['root'], \"DATA_S2\", f\"S2_{patch_id}.npy\")\n",
    "            ).astype(np.float32)\n",
    "        np.save(\n",
    "            os.path.join(params['out_folder'], f\"S2_{patch_id}\"),\n",
    "            data[timestamps]\n",
    "            )\n",
    "\n",
    "def drop_clouds(root, cloud_analisys, out_folder, cloud_treshold=0.25, num_threads=-1):\n",
    "    print(\"Reading cloud analisys...\")\n",
    "    cloud_ta = gpd.read_file(cloud_analisys)\n",
    "    cloud_ta.cloud_percentage = cloud_ta.cloud_percentage.astype(float)\n",
    "    cloud_ta.drop(cloud_ta[cloud_ta.cloud_percentage >= cloud_treshold].index, inplace=True)\n",
    "    cloud_ta.timestamp = cloud_ta.timestamp.astype(int)\n",
    "\n",
    "    selected_tmps = {}\n",
    "    print(f\"Dropping timestamps with c_per < {cloud_treshold}...\")\n",
    "    for _, patch in cloud_ta.iterrows():\n",
    "        patch_id, timestamp, c_per, _ = patch\n",
    "        patch_id = patch_id.split('_')[1]\n",
    "\n",
    "        if patch_id not in selected_tmps:\n",
    "            selected_tmps[patch_id] = []\n",
    "\n",
    "        selected_tmps[patch_id].append(timestamp)\n",
    "\n",
    "    selected_df = {\n",
    "        'id': [],\n",
    "        'timestamps': [],\n",
    "    }\n",
    "    cloud_aux = {\n",
    "        'id': [],\n",
    "        'tmps_count': [],\n",
    "    }\n",
    "    for id in selected_tmps:\n",
    "        selected_df['id'].append(id)\n",
    "        cloud_aux['id'].append(id)\n",
    "        selected_df['timestamps'].append(selected_tmps[id])\n",
    "        cloud_aux['tmps_count'].append(len(selected_tmps[id]))\n",
    "\n",
    "    pd.DataFrame(cloud_aux).to_csv(\"cloud_aux.csv\", index=False)\n",
    "    selected_df = pd.DataFrame(selected_df)\n",
    "\n",
    "    num_processes = mp.cpu_count() if num_threads == -1 else num_threads\n",
    "    chuncks = np.array_split(selected_df, num_processes)\n",
    "    print(\"Pool processing...\")\n",
    "    params = {\n",
    "        'root': root,\n",
    "        'out_folder': out_folder,\n",
    "    }\n",
    "    with mp.Pool(num_processes) as pool:\n",
    "        pool.map(pool_processing, zip([params] * num_processes, chuncks,))\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d98f12e-79f0-4545-b0f3-f254e692f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cloud analisys...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /opt/conda/share/proj failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping timestamps with c_per < 0.25...\n",
      "Pool processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "drop_clouds(\n",
    "    pastis_dir,\n",
    "    \"./pastis_cloud_analysis.csv\",\n",
    "    os.path.join(\"pastis_cloud_refined\"),\n",
    "    num_threads=mp.cpu_count() * 4 // 5\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
